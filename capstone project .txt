Capstone Project:

Bank Loan data analysis

1.Project to analyze the bank loan data set. by using HDFS, Hive, Spark and  MongoDB

2.Getting data into HDFS environment then creating database in hive 

3.Creating sql data frame from the result of the hive query using Pyspark 

4.Next converting the result  into dictionary and loading it into the mongodb using Pymongo.  








FOLOWING ARE THE STEPS FOLLOWED FOR GETTING THE REQUIRED OUTCOME OF CAPSTONE PROJECT USING BANK_LOAN_DATA.CSV


1) load the data in hdfs environment
2)hive use to create database and table after loading data in the table from hdfs environment
3)pyspark -to create the dataframes using sql commands on table in hive
4) saving the output of pyspark in mongodb using pymongo 




[hadoop@ip-172-31-23-106 ~]$ hdfs dfs -cp s3://shubham9991-05-51/Bank_loan_data.csv /bank_loan
23/02/04 12:53:59 INFO s3n.S3NativeFileSystem: Opening 's3://shubham9991-05-51/Bank_loan_data.csv' for reading
[hadoop@ip-172-31-23-106 ~]$ hdfs dfs -ls /bank_loan
-rw-r--r--   1 hadoop hdfsadmingroup    1768017 2023-02-04 12:53 /bank_loan
[hadoop@ip-172-31-23-106 ~]$ hive

Logging initialized using configuration in file:/etc/hive/conf.dist/hive-log4j2.properties Async: false
hive> create database bank_loan;
OK
Time taken: 0.825 seconds
hive> use bank_loan;
OK
Time taken: 0.039 seconds
hive> create table bank_loan (LoanID varchar(30) , CustomerID varchar(30) , CurrentLoanAmount int , Term varchar(20) , CreditScore int , AnnualIncome int, Yearsincurrentjob  varchar(20) , HomeOwnership varchar(20), Purpose varchar(20) , MonthlyDebt int , YearsofCreditHistory float, Monthssincelastdelinquent float, NumberofOpenAccounts int , NumberofCreditProblems int , CurrentCreditBalance int , MaximumOpenCredit int , Bankruptcies int , TaxLiens int ) row format delimited fields terminated by ',' stored as textfile;
OK
Time taken: 0.444 seconds
hive> load data inpath '/bank_loan' into table bank_loan;
Loading data to table bank_loan.bank_loan
OK
Time taken: 0.535 seconds
hive> select * from bank_loan limit 3;
OK
f738779f-c726-40dc-92cf-689d73  ded0b3c3-6bf4-4091-8726-47039f  611314  Short Term      747     2074116 10+ years       Home Mortgage   Debt Consolidation      42000  21.8     NULL    9       0       621908  1058970 0       0
6dcc0947-164d-476c-a1de-3ae728  1630e6e3-34e3-461a-8fda-09297d  266662  Short Term      734     1919190 10+ years       Home Mortgage   Debt Consolidation      36624  19.4     NULL    11      0       679573  904442  0       0
f7744d01-894b-49c3-8777-fc6431  2c60938b-ad2b-4702-804d-eeca43  153494  Short Term      709     871112  2 years Rent    Debt Consolidation      8391    12.5    10.0   10       0       38532   388036  0       0
Time taken: 1.246 seconds, Fetched: 3 row(s)
hive> quit;
[hadoop@ip-172-31-23-106 ~]$ pyspark
Python 3.7.16 (default, Dec 15 2022, 23:24:54)
[GCC 7.3.1 20180712 (Red Hat 7.3.1-15)] on linux
Type "help", "copyright", "credits" or "license" for more information.
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
23/02/04 12:59:05 WARN HiveConf: HiveConf of name hive.server2.thrift.url does not exist
23/02/04 12:59:07 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 2.4.8-amzn-2
      /_/

Using Python version 3.7.16 (default, Dec 15 2022 23:24:54)
SparkSession available as 'spark'.
>>> import pyspark
>>> dbh=spark.sql("use bank_loan")
23/02/04 12:59:57 WARN HiveConf: HiveConf of name hive.server2.thrift.url does not exist
>>> df=spark.sql("select LoanID ,CurrentLoanAmount from bank_loan order by CurrentLoanAmount  limit 5");
>>> df.show()
+--------------------+-----------------+
|              LoanID|CurrentLoanAmount|
+--------------------+-----------------+
|4fe45d92-7af3-483...|            19470|
|8e00abc0-5851-42a...|            21472|
|ba6b7eec-4549-486...|            21516|
|3c0c3e56-d33e-4ff...|            21560|
|e6c89039-92eb-480...|            21560|
+--------------------+-----------------+

>>> import pymongo
>>> from pymongo import MongoClient
>>> client=MongoClient('mongodb://127.0.0.1',27017)
>>> db=client['bankl']
>>> df_list=[list(row) for row in df.collect()]
>>> import numpy as np                                                          i
>>> ar=np.array(df_list)
>>> dict={}
>>> for i ,collumn in enumerate(df.columns):
...       dict[collumn]=list(ar[:,i])
...
>>> coll=db.lowest5
>>> coll.insert_one(dict)
<pymongo.results.InsertOneResult object at 0x7fb496505490>
>>> cur=coll.find()
>>> for i in cur:
...  print(i)
...
{'_id': ObjectId('63de58b42892765cb2691c56'), 'LoanID': ['4fe45d92-7af3-483f-8742-c698df', '8e00abc0-5851-42ab-b25f-9855ab', 'ba6b7eec-4549-486d-9ed6-ce3068', 'e6c89039-92eb-4804-b77d-fb7fec', '3c0c3e56-d33e-4ff9-9dd2-4aa673'], 'CurrentLoanAmount': ['19470', '21472', '21516', '21560', '21560']}
>>> quit()
[hadoop@ip-172-31-23-106 ~]$ mongosh
Current Mongosh Log ID: 63de59633ade6c0aeed75da7
Connecting to:          mongodb://127.0.0.1:27017/?directConnection=true&serverSelectionTimeoutMS=2000&appName=mongosh+1.6.2
Using MongoDB:          6.0.4
Using Mongosh:          1.6.2

For mongosh info see: https://docs.mongodb.com/mongodb-shell/

------
   The server generated these startup warnings when booting
   2023-02-04T02:14:09.450+00:00: Access control is not enabled for the database. Read and write access to data and configuration is unrestricted
   2023-02-04T02:14:09.450+00:00: vm.max_map_count is too low
------

------
   Enable MongoDB's free cloud-based monitoring service, which will then receive and display
   metrics about your deployment (disk utilization, CPU, operation statistics, etc).

   The monitoring data will be available on a MongoDB website with a unique URL accessible to you
   and anyone you share the URL with. MongoDB may use this information to make product
   improvements and to suggest MongoDB products and deployment options to you.

   To enable free monitoring, run the following command: db.enableFreeMonitoring()
   To permanently disable this reminder, run the following command: db.disableFreeMonitoring()
------

gave an example with one sql query simillarly all the sql queries for all questions were done and created collections 
far all query  and saved output in mongodb



below are the all the collections created



test> show dbs
admin   40.00 KiB
bankl    1.48 MiB
config  72.00 KiB
local   40.00 KiB
test> use bankl
switched to db bankl



bankl> show collections
agg_sum_of_credit_score
agg_sum_total_current_loan
aggsumof_totalcurrentloan
avgmonthlydebt
longloan
low5
lowest5
maxcreditscore
shortloan
sumbankruptcies
top5
yearinjob10
yearinjob102



sql queries for all questions 
-- 1.Create a dataframe with the Customer IDs having top 5 current loan amounts  and save the result in MongoDB?

select LoanID ,CurrentLoanAmount from bank_loan order by CurrentLoanAmount desc limit 5;

-- 2.Create a dataframe with the Customer IDs having the lowest 5 current loan amounts  and save the result in MongoDB?

select LoanID ,CurrentLoanAmount from bank_loan order by CurrentLoanAmount limit 5;

-- 3.Create a dataframe of Customer IDs who have taken the Short Term Loan and include their total Current Loan Amount and save the result in MongoDB? 

select  CustomerID ,SUM(CurrentLoanAmount) over (partition by CustomerID ) loanamt  from bank_loan where Term='Short Term' ;

-- 4.Create a dataframe of Customer IDs who have taken the Long Term Loan and include their total Current Loan Amount and save the result in MongoDB?
 
select  CustomerID ,SUM(CurrentLoanAmount) over (partition by CustomerID ) loanamt  from bank_loan where Term='Long Term' ;


-- 5.Count how many Bankruptcies are present?

select sum(Bankruptcies) from bank_loan;



-- 6.Group the data based on Term and find the average monthly debt.

select term,avg(MonthlyDebt) amd  FROM bank_loan group by term ;

-- 7.Create a dataframe of the customers who have 10 + years experience in their current job. Include their Annual Income

select CustomerID,AnnualIncome from bank_loan where Yearsincurrentjob='10+ years';

-- 8.Group the data based on Home ownership and Term. Find the aggregated sum of the total current loan.

select  HomeOwnership,Term ,sum(CurrentLoanAmount) s from bank_loan group by  HomeOwnership,Term order by homeownership;

-- 9.Find the highest credit score for short term and long term customers.

select Term,max(creditscore) from bank_loan group  by Term;



-- 10. Group the data based on years in current job and Home ownership and find the aggregated sum of credit score.

select  yearsincurrentjob ,Homeownership,sum(CreditScore) from bank_loan  group  by yearsincurrentjob ,Homeownership order by yearsincurrentjob desc ,Homeownership;




q1)-- output saved in mongodb
{'_id': ObjectId('63ddc8097d12c763f5fd0437'), 'LoanID': ['1114a7c5-4cea-49c1-b4e3-7ca218', 'ce6562c3-f100-4342-8fe8-f03d33', 'e840a6a8-28a2-4b38-9863-390381', 'cb6f7b00-62e7-4e18-8e73-73e603', 'eda0e007-b2b1-486a-b4ce-58adef'], 'CurrentLoanAmount': ['99999999', '99999999', '99999999', '99999999', '99999999']}


q2)-- output saved in mongodb
{"_id": ObjectId('63ddc96b7d12c763f5fd0438'), "LoanID": ['4fe45d92-7af3-483f-8742-c698df', '8e00abc0-5851-42ab-b25f-9855ab', 'ba6b7eec-4549-486d-9ed6-ce3068', 'e6c89039-92eb-4804-b77d-fb7fec', '3c0c3e56-d33e-4ff9-9dd2-4aa673'], "CurrentLoanAmount": ['19470', '21472', '21516', '21560', '21560']}



simillarly all the outputs of sql queries given above were saved in mongodb
